[runtime]
; The emcee sampler, which uses the Goodman & Weare algorithm
sampler = emcee
root = ${PWD}
verbosity = quiet

[DEFAULT]
; This value is used below as %(planck_path)s
planck_path = likelihood/planck2018/baseline/plc_3.0
planck_data = likelihood/planck2018/data

[pipeline]
; We use two likelihoods, Pantheon (for high redshift) and
; Riess 2011 to anchor H0, which is otherwise degenerate
; with the nuisance parameter M
modules = consistency linder_w_phi_model camb sample_rdh desi planck act_dr6_lens
values = inis/desi_planck_lodha24_values.ini
extra_output= 
;cosmological_parameters/sigma_8 cosmological_parameters/omega_m
debug=F
timing=F

[output]
filename = output/desi_planck_lodha24_cmb_wlensing.txt
format = text

[maxlike]
; we save the best parameters as a new values.ini file so you can start
; future runs from there
output_ini = output/w_maxlike.ini
; A covariance can only be output by some 
; optimization methods (those that find an approximation to it numerically)
output_covmat = output/w_covariance.txt
tolerance = 1e-2

max_posterior = T

; The BFGS method seems to find it a bit harder to actually locate
; the peak, but once it's there it provides you with covariance
; matrix estimate
; method = Nelder-Mead
method = BFGS

; Any minimizer available in scipy can be specified here - they are:
; Nelder-Mead
; Powell
; CG
; BFGS
; Newton-CG
; L-BFGS-B
; TNC
; COBYLA
; SLSQP
; dogleg
; trust-ncg


; we could change sampler = maxlike to sampler=emcee at the start
; to use this instead.
[emcee]
; The emcee sampler uses the concept of walkers, a collection
; of live points.  Sampling is done along lines that connect
; pairs of walkers.  The number of walkers must be at least
; 2*nparam + 1, but in general more than that usually works
; better.
walkers = 96
; This many samples is overkill, just to make the plots
; look a lot nicer
samples = 4000
; This is the interval at which convergence diagnostics
; are performed
nsteps = 10

[linder_w_phi_model]
file = background/linder_w_phi_model/linder_w_phi_model.py
zmax = 3.0
nz = 301

[planck]
file = likelihood/planck_py/planck_py_interface.py
use_low_ell_bins = T
spectra = TTTEEE
year = 2018

; [planck]
; ;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
; ;without CMB lensing
; file = likelihood/planck2018/planck_interface.so
; data_1 = %(planck_path)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
; data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
; data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

[p-TTTEEE_lite-lowE-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;with CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = %(planck_data)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;low ell TT
data_2 = %(planck_data)s/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE 
data_3 = %(planck_data)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik
;lensing
lensing_1 = %(planck_data)s/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[act_dr6_lens]
file = ./likelihood/act-dr6-lens/act_dr6_lenslike_interface.py
like_corrections = T
variant = act_baseline ; actplanck_baseline

[camb]
; ; For background-only data we do not need a full
; ; Boltzmann evaluation, just D(z), etc.
; ; Setting mode=background means we get this.
; file = boltzmann/camb/camb_interface.py
; ; mode = background
; ; feedback = 0
; use_tabulated_w = T
; use_ppf_w = T

; ; from planck_lite.ini
; mode = cmb
; lmax = 2800          ;max ell to use for cmb calculation
; feedback=2         ;amount of output to print
; AccuracyBoost=1.1 ;CAMB accuracy boost parameter
; do_tensors = True   ;include tensor modes
; do_lensing = True    ;lensing is required w/ Planck data
; NonLinear = lens
accurate_massive_neutrino_transfers = F
; halofit_version = takahashi

; ; We need quite fine redshift spacing, because the supernovae
; ; go down to low z where things are pretty sensitive
nz_background = 300
zmin_background = 0.0
zmax_background = 3.0

file = boltzmann/camb/camb_interface.py
mode = cmb
lmax = 4000          ;max ell to use for cmb calculation
lens_margin = 1250
lens_potential_accuracy = 4
feedback=0         ;amount of output to print
AccuracyBoost=1.0 ;CAMB accuracy boost parameter
lSampleBoost = 1.0
lAccuracyBoost = 1.0
do_tensors = T   ;include tensor modes
do_lensing = T    ;lensing is required w/ Planck data
NonLinear = lens
theta_H0_range = "20 100"
halofit_version = takahashi


[des_sn5yr]
file = likelihood/des-sn5yr/des_sn5yr.py
; likelihood_only = T

[sample_rdh]
file = utility/rescale_distances_rdh/rescale_distances_rdh.py

[desi]
file = likelihood/bao/desi1-dr1/desi1_dr1.py
desi_data_sets = BGS,LRG1,LRG2,LRG3+ELG1,ELG2,QSO,Lya QSO

[pantheon_plus]
file = likelihood/pantheon_plus/pantheon_plus_shoes.py
likelihood_only = T
include_shoes = F

; The Riess 11 likelihood anchors H0 for us
[riess21]
file = likelihood/riess21/riess21.py

; The consistency module translates between our chosen parameterization
; and any other that modules in the pipeline may want (e.g. camb)
[consistency]
file = utility/consistency/consistency_interface.py

; This is the sampler used for the DES-Y3 releases.
[polychord]
base_dir = output/linder-wphi-polychord-checkpoints
polychord_outfile_root = linder-wphi
resume = F
feedback = 3
fast_fraction = 0.1

;Minimum settings
live_points = 250
num_repeats = 30
tolerance = 0.1

;Settings for paper runs
; live_points = 500
; num_repeats=60
; tolerance=0.01
; boost_posteriors=10.0
