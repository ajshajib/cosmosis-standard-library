[runtime]
; The emcee sampler, which uses the Goodman & Weare algorithm
sampler = polychord
root = ${PWD}
verbosity = quiet

[DEFAULT]
; This value is used below as %(planck_path)s
planck_path = likelihood/planck2018/baseline/plc_3.0

[pipeline]
; We use two likelihoods, Pantheon (for high redshift) and
; Riess 2011 to anchor H0, which is otherwise degenerate
; with the nuisance parameter M
modules = consistency w_phi_cdm_model camb planck act_dr6_lens desi_sdss des_sn5yr
values = inis/all_values.ini
priors = inis/planck_priors.ini
extra_output =
debug=F
timing=F

[output]
filename = output/all_polychord.txt
format = text

[maxlike]
; we save the best parameters as a new values.ini file so you can start
; future runs from there
output_ini = output/w_maxlike.ini
; A covariance can only be output by some 
; optimization methods (those that find an approximation to it numerically)
output_covmat = output/w_covariance.txt
tolerance = 1e-2

max_posterior = T

; The BFGS method seems to find it a bit harder to actually locate
; the peak, but once it's there it provides you with covariance
; matrix estimate
; method = Nelder-Mead
method = BFGS

; Any minimizer available in scipy can be specified here - they are:
; Nelder-Mead
; Powell
; CG
; BFGS
; Newton-CG
; L-BFGS-B
; TNC
; COBYLA
; SLSQP
; dogleg
; trust-ncg


; we could change sampler = maxlike to sampler=emcee at the start
; to use this instead.
[emcee]
; The emcee sampler uses the concept of walkers, a collection
; of live points.  Sampling is done along lines that connect
; pairs of walkers.  The number of walkers must be at least
; 2*nparam + 1, but in general more than that usually works
; better.
walkers = 96
; This many samples is overkill, just to make the plots
; look a lot nicer
samples = 2000
; This is the interval at which convergence diagnostics
; are performed
nsteps = 5

[polychord]
base_dir = output/all-polychord-checkpoints
polychord_outfile_root = all
resume = F
feedback = 3
fast_fraction = 0.1

;Minimum settings
live_points = 170
num_repeats = 30
tolerance = 0.1

;Settings for paper runs
; live_points = 500
; num_repeats=60
; tolerance=0.01
; boost_posteriors=10.0

[w_phi_cdm_model]
file = background/w_phi_cdm_model/w_phi_cdm_model.py
zmax = 3.0
nz = 301

[planck_py]
file = likelihood/planck_py/planck_py_interface.py
use_low_ell_bins = T
spectra = TTTEEE
year = 2018

[planck_lite]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = %(planck_path)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;low ell TT
data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE 
data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

;;CMB;;
[planck]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE
data_1 = %(planck_path)s/hi_l/plik/plik_rd12_HM_v22b_TTTEEE.clik
;low ell TT
data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE 
data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

[p-TTTEEE_lite-lowE]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = %(planck_path)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;low ell TT
data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE 
data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

[p-TTTEEE-lowE-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;with CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE
data_1 = %(planck_path)s/hi_l/plik/plik_rd12_HM_v22b_TTTEEE.clik
;low ell TT
data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE 
data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik
;lensing
lensing_1 = %(planck_path)s/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[p-TTTEEE_lite-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = %(planck_path)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;lensing
lensing_1 = %(planck_path)s/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[p-TTTEEE_lite-lowE-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = %(planck_path)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;low ell TT
data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE 
data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik
;lensing
lensing_1 = %(planck_path)s/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[p-lensing]
;Planck 2018 CMB lensing
file = likelihood/planck2018/planck_interface.so
;lensing
lensing_1 = %(planck_path)s/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8_CMBmarged.clik_lensing

[act_dr6_lens]
file = ./likelihood/act-dr6-lens/act_dr6_lenslike_interface.py
variant = actplanck_extended ; actplanck_extended ; actplanck_baseline
lens_only = False ; False when combining with any primary CMB measurement, then a covariance matrix will be used which has been CMB marginalized
like_corrections = True # should be False if lens_only is True

[camb]
file = boltzmann/camb/camb_interface.py
mode = cmb
lmax = 4000          ;max ell to use for cmb calculation
lens_margin = 1250 ; delta_l_max? 800 recommended by ACT
lens_potential_accuracy = 4
feedback = 0         ;amount of output to print
AccuracyBoost = 1.1 ;CAMB accuracy boost parameter
lSampleBoost = 1.0
lAccuracyBoost = 1.0
do_tensors = T   ;include tensor modes
do_lensing = T    ;lensing is required w/ Planck data
NonLinear = lens
theta_H0_range = "20 100"
halofit_version = mead2020

use_tabulated_w = T
use_ppf_w = T
accurate_massive_neutrino_transfers = F
; ; We need quite fine redshift spacing, because the supernovae
; ; go down to low z where things are pretty sensitive
nz_background = 300
zmin_background = 0.0
zmax_background = 3.0
want_chistar=T
n_logz = 100
zmax_logz = 1100.0

[des_sn5yr]
file = likelihood/des-sn5yr/des_sn5yr.py
; likelihood_only = T

[sample_rdh]
file = utility/rescale_distances_rdh/rescale_distances_rdh.py

[desi]
file = likelihood/bao/desi1-dr1/desi1_dr1.py
desi_data_sets = BGS,LRG1,LRG2,LRG3+ELG1,ELG2,QSO,Lya QSO

[desi_sdss]
file = likelihood/bao/desi_sdss/desi_sdss.py
desi_data_sets = BOSS_MGS,BOSS_galaxy1,BOSS_galaxy2,LRG2,LRG3+ELG1,ELG2,QSO,Lya QSO combined

[pantheon_plus]
file = likelihood/pantheon_plus/pantheon_plus_shoes.py
likelihood_only = T
include_shoes = F

; The Riess 11 likelihood anchors H0 for us
[riess21]
file = likelihood/riess21/riess21.py

; The consistency module translates between our chosen parameterization
; and any other that modules in the pipeline may want (e.g. camb)
[consistency]
file = utility/consistency/consistency_interface.py
