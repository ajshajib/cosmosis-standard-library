[runtime]
; The emcee sampler, which uses the Goodman & Weare algorithm
sampler = test
root = ${PWD}
verbosity = quiet

[DEFAULT]
; This value is used below as %(planck_path)s
planck_path = likelihood/planck2018/baseline/plc_3.0

[pipeline]
; We use two likelihoods, Pantheon (for high redshift) and
; Riess 2011 to anchor H0, which is otherwise degenerate
; with the nuisance parameter M
modules = consistency linder_w_phi_model camb planck act_dr6_lens desi
values = inis/desi_planck_lodha24_values.ini
priors = inis/planck_priors.ini
extra_output =
debug=F
timing=T

[output]
filename = output/desi_planck_full_act_lodha_2_test.txt
format = text

[maxlike]
; we save the best parameters as a new values.ini file so you can start
; future runs from there
output_ini = output/w_maxlike.ini
; A covariance can only be output by some 
; optimization methods (those that find an approximation to it numerically)
output_covmat = output/w_covariance.txt
tolerance = 1e-2

max_posterior = T

; The BFGS method seems to find it a bit harder to actually locate
; the peak, but once it's there it provides you with covariance
; matrix estimate
; method = Nelder-Mead
method = BFGS

; Any minimizer available in scipy can be specified here - they are:
; Nelder-Mead
; Powell
; CG
; BFGS
; Newton-CG
; L-BFGS-B
; TNC
; COBYLA
; SLSQP
; dogleg
; trust-ncg


; we could change sampler = maxlike to sampler=emcee at the start
; to use this instead.
[emcee]
; The emcee sampler uses the concept of walkers, a collection
; of live points.  Sampling is done along lines that connect
; pairs of walkers.  The number of walkers must be at least
; 2*nparam + 1, but in general more than that usually works
; better.
walkers = 96
; This many samples is overkill, just to make the plots
; look a lot nicer
samples = 2000
; This is the interval at which convergence diagnostics
; are performed
nsteps = 5

[polychord]
base_dir = output/desi-polychord-checkpoints
polychord_outfile_root = desi_planck
resume = T
feedback = 3
fast_fraction = 0.1

;Minimum settings
live_points = 250
num_repeats = 30
tolerance = 0.1

;Settings for paper runs
; live_points = 500
; num_repeats=60
; tolerance=0.01
; boost_posteriors=10.0

[w_phi_cdm_model]
file = background/w_phi_cdm_model/w_phi_cdm_model.py
zmax = 3.0
nz = 301

[linder_w_phi_model]
file = background/linder_w_phi_model/linder_w_phi_model.py
zmax = 3.0
nz = 301

[planck_lite]
file = likelihood/planck_py/planck_py_interface.py
use_low_ell_bins = T
spectra = TTTEEE
year = 2018

[planck]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
data_1 = %(planck_path)s/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
data_2 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
data_3 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

[act_dr6_lens]
file = ./likelihood/act-dr6-lens/act_dr6_lenslike_interface.py
variant = actplanck_extended ; actplanck_baseline
lens_only = False ; False when combining with any primary CMB measurement, then a covariance matrix will be used which has been CMB marginalized
like_corrections = True # should be False if lens_only is True

[camb]
; ; For background-only data we do not need a full
; ; Boltzmann evaluation, just D(z), etc.
; ; Setting mode=background means we get this.
; file = boltzmann/camb/camb_interface.py
; ; mode = background
; ; feedback = 0
; use_tabulated_w = T
; use_ppf_w = T

; ; from planck_lite.ini
; mode = cmb
; lmax = 2800          ;max ell to use for cmb calculation
; feedback=0         ;amount of output to print
; AccuracyBoost=1.1 ;CAMB accuracy boost parameter
; do_tensors = True   ;include tensor modes
; do_lensing = True    ;lensing is required w/ Planck data
; NonLinear = lens
; accurate_massive_neutrino_transfers = F
; halofit_version = takahashi

; ; We need quite fine redshift spacing, because the supernovae
; ; go down to low z where things are pretty sensitive
; nz_background = 300
; zmin_background = 0.0
; zmax_background = 3.0

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; ; For background-only data we do not need a full
; ; Boltzmann evaluation, just D(z), etc.
; ; Setting mode=background means we get this.
; file = boltzmann/camb/camb_interface.py
; ; mode = background
; ; feedback = 0
use_tabulated_w = T
use_ppf_w = T

; ; from planck_lite.ini
; mode = cmb
; lmax = 2800          ;max ell to use for cmb calculation
; feedback=2         ;amount of output to print
; AccuracyBoost=1.1 ;CAMB accuracy boost parameter
; do_tensors = True   ;include tensor modes
; do_lensing = True    ;lensing is required w/ Planck data
; NonLinear = lens
accurate_massive_neutrino_transfers = F
; halofit_version = takahashi

; ; We need quite fine redshift spacing, because the supernovae
; ; go down to low z where things are pretty sensitive
nz_background = 300
zmin_background = 0.0
zmax_background = 3.0

want_chistar=T
n_logz = 100
zmax_logz = 1100.0

file = boltzmann/camb/camb_interface.py
mode = cmb
lmax = 4000          ;max ell to use for cmb calculation
lens_margin = 1250 ; delta_l_max? 800 recommended by ACT
lens_potential_accuracy = 4
feedback = 0         ;amount of output to print
AccuracyBoost = 1.1 ;CAMB accuracy boost parameter
lSampleBoost = 1.0
lAccuracyBoost = 1.0
do_tensors = T   ;include tensor modes
do_lensing = T    ;lensing is required w/ Planck data
NonLinear = lens
theta_H0_range = "20 100"
halofit_version = takahashi

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

[des_sn5yr]
file = likelihood/des-sn5yr/des_sn5yr.py
; likelihood_only = T

[sample_rdh]
file = utility/rescale_distances_rdh/rescale_distances_rdh.py

[desi]
file = likelihood/bao/desi1-dr1/desi1_dr1.py
desi_data_sets = BGS,LRG1,LRG2,LRG3+ELG1,ELG2,QSO,Lya QSO

[pantheon_plus]
file = likelihood/pantheon_plus/pantheon_plus_shoes.py
likelihood_only = T
include_shoes = F

; The Riess 11 likelihood anchors H0 for us
[riess21]
file = likelihood/riess21/riess21.py

; The consistency module translates between our chosen parameterization
; and any other that modules in the pipeline may want (e.g. camb)
[consistency]
file = utility/consistency/consistency_interface.py
